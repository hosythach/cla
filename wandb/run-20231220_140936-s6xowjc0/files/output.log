/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.
  @numba.jit
[12/20/23 14:09:56] [34mINFO    [39m [1m2023[22m-[1m12[22m-[1m20[22m [1m14:09:56[22m,[1m479[22m [1m[[22mINFO[1m][22m logs and  ]8;id=960869;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py\main.py]8;;\:]8;id=259631;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py#42\42]8;;\
                             outputs are saved to
                             outputs/12_20_14_09_56
                    [34mINFO    [39m [1m2023[22m-[1m12[22m-[1m20[22m [1m14:09:56[22m,[1m481[22m [1m[[22mINFO[1m][22m           ]8;id=378124;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py\main.py]8;;\:]8;id=734713;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py#44\44]8;;\
                             seed: [1m42
                             train_mode: [3mTrue
                             model_name: openai/whisper-large-v2
                             model_force_lang: english
                             dataset_name: gigaspeech
                             dataset_path:
                             [35m/home/thachhs/clau/clairaudience/data/pr
                             [35moj_asr/hf_dd_data/speechcolab/gigaspeech
                             [35m/[95mxs
                             train_with_prompts: [3mTrue
                             valid_with_prompts: [3mTrue
                             test_with_prompts: [3mTrue
                             train_prompt_info: [1m[[32m[22m'[ domain: tag1, 
                             [32mtag2, tag3]'[39m[1m]
                             valid_prompt_info: [1m[[32m[22m'[ domain: tag1, 
                             [32mtag2, tag3]'[39m[1m]
                             test_prompt_info: [1m[[32m[22m'[ domain: tag1, 
                             [32mtag2, tag3]'[39m[1m]
                             dataset_split: test
                             num_beams: [1m3
                             output_dir: outputs
                             cache_dir: outputs/cache_dir
                             dataset_num_proc: [1m8
                             num_subsamples: [1m-1
                             num_train_subsamples: [1m-1
                             num_valid_subsamples: [1m100
                             num_test_subsamples: [1m-1
                             use_kl_loss: [3mFalse
                             kl_coeff: [1m0.2
                             kl_type: KL_div
                             use_cross_attn: [3mTrue
                             use_no_speech_bias: [3mFalse
                             use_null_inputs: [3mFalse
                             max_target_positions: [1m448
                             learning_rate: [1m2e-05
                             per_device_train_batch_size: [1m1
                             gradient_accumulation_steps: [1m16
                             weight_decay: [1m0
                             max_steps: [1m2000
                             warmup_steps: [1m200
                             dataloader_num_workers: [1m1
                             per_device_eval_batch_size: [1m1
                             eval_steps: [1m50
                             evaluation_strategy: no
                             logging_steps: [1m10
                             save_steps: [1m50
                             predict_with_generate: [3mTrue
                             resume_from_checkpoint: [3mNone
Seed set to 42
                    [34mINFO    [39m [1m2023[22m-[1m12[22m-[1m20[22m [1m14:09:56[22m,[1m486[22m [1m[[22mINFO[1m][22m Start     ]8;id=256787;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py\main.py]8;;\:]8;id=234053;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py#51\51]8;;\
                             Loading Model
[12/20/23 14:10:46] [34mINFO    [39m [1m2023[22m-[1m12[22m-[1m20[22m [1m14:10:46[22m,[1m359[22m [1m[[22mINFO[1m][22m Load    ]8;id=571858;file:///home/thachhs/clau/clairaudience/clairaudience/../clairaudience/model.py\model.py]8;;\:]8;id=91161;file:///home/thachhs/clau/clairaudience/clairaudience/../clairaudience/model.py#782\782]8;;\
                             model from whisper pretrained
                             checkpoint: openai/whisper-large-v2
[12/20/23 14:10:47] [34mINFO    [39m [1m2023[22m-[1m12[22m-[1m20[22m [1m14:10:47[22m,[1m274[22m [1m[[22mINFO[1m][22m Start     ]8;id=229258;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py\main.py]8;;\:]8;id=243962;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py#55\55]8;;\
                             Loading Dataset - gigaspeech
                    [34mINFO    [39m [1m2023[22m-[1m12[22m-[1m20[22m [1m14:10:47[22m,[1m330[22m [1m[[22mINFO[1m][22m  ]8;id=681453;file:///home/thachhs/clau/clairaudience/clairaudience/../clairaudience/data_process.py\data_process.py]8;;\:]8;id=735392;file:///home/thachhs/clau/clairaudience/clairaudience/../clairaudience/data_process.py#170\170]8;;\
                             Subsample the validation
                             dataset. Only use [1m100[22m samples
                             of the validation dataset
                             [1m(6750)
Traceback (most recent call last):
  File "/home/thachhs/clau/clairaudience/./clairaudience/main.py", line 131, in <module>
    run(cfg)
  File "/home/thachhs/clau/clairaudience/./clairaudience/main.py", line 92, in run
    trainer = ClairaudienceTrainer(
              ^^^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/clau/clairaudience/clairaudience/../clairaudience/trainer.py", line 63, in __init__
    super().__init__(
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/transformers/trainer_seq2seq.py", line 56, in __init__
    super().__init__(
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/transformers/trainer.py", line 551, in __init__
    self.init_git_repo(at_init=True)
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/transformers/trainer.py", line 3534, in init_git_repo
    self.repo = Repository(self.args.output_dir, clone_from=repo_name, token=self.args.hub_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/huggingface_hub/repository.py", line 516, in __init__
    self.clone_from(repo_url=clone_from)
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/huggingface_hub/repository.py", line 680, in clone_from
    raise EnvironmentError(
OSError: Tried to clone a repository in a non-empty folder that isn't a git repository ('/home/thachhs/clau/clairaudience/outputs/12_20_14_09_56'). If you really want to do this, do it manually:
 cd /home/thachhs/clau/clairaudience/outputs/12_20_14_09_56 && git init && git remote add origin && git pull origin main
 or clone repo to a new folder and move your existing files there afterwards.
/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.
  @numba.jit
[12/20/23 14:24:11] [34mINFO    [39m [1m2023[22m-[1m12[22m-[1m20[22m [1m14:24:11[22m,[1m157[22m [1m[[22mINFO[1m][22m logs and  ]8;id=778907;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py\main.py]8;;\:]8;id=934353;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py#42\42]8;;\
                             outputs are saved to
                             outputs/12_20_14_24_11
                    [34mINFO    [39m [1m2023[22m-[1m12[22m-[1m20[22m [1m14:24:11[22m,[1m160[22m [1m[[22mINFO[1m][22m           ]8;id=285095;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py\main.py]8;;\:]8;id=445067;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py#44\44]8;;\
                             seed: [1m42
                             train_mode: [3mTrue
                             model_name: openai/whisper-large-v2
                             model_force_lang: english
                             dataset_name: gigaspeech
                             dataset_path:
                             [35m/home/thachhs/clau/clairaudience/data/pr
                             [35moj_asr/hf_dd_data/speechcolab/gigaspeech
                             [35m/[95mxs
                             train_with_prompts: [3mTrue
                             valid_with_prompts: [3mTrue
                             test_with_prompts: [3mTrue
                             train_prompt_info: [1m[[32m[22m'[ domain: tag1, 
                             [32mtag2, tag3]'[39m[1m]
                             valid_prompt_info: [1m[[32m[22m'[ domain: tag1, 
                             [32mtag2, tag3]'[39m[1m]
                             test_prompt_info: [1m[[32m[22m'[ domain: tag1, 
                             [32mtag2, tag3]'[39m[1m]
                             dataset_split: test
                             num_beams: [1m3
                             output_dir: outputs
                             cache_dir: outputs/cache_dir
                             dataset_num_proc: [1m8
                             num_subsamples: [1m-1
                             num_train_subsamples: [1m-1
                             num_valid_subsamples: [1m100
                             num_test_subsamples: [1m-1
                             use_kl_loss: [3mFalse
                             kl_coeff: [1m0.2
                             kl_type: KL_div
                             use_cross_attn: [3mTrue
                             use_no_speech_bias: [3mFalse
                             use_null_inputs: [3mFalse
                             max_target_positions: [1m448
                             learning_rate: [1m2e-05
                             per_device_train_batch_size: [1m1
                             gradient_accumulation_steps: [1m16
                             weight_decay: [1m0
                             max_steps: [1m2000
                             warmup_steps: [1m200
                             dataloader_num_workers: [1m1
                             per_device_eval_batch_size: [1m1
                             eval_steps: [1m50
                             evaluation_strategy: no
                             logging_steps: [1m10
                             save_steps: [1m50
                             predict_with_generate: [3mTrue
                             resume_from_checkpoint: [3mNone
                    [34mINFO    [39m [1m2023[22m-[1m12[22m-[1m20[22m [1m14:24:11[22m,[1m163[22m [1m[[22mINFO[1m][22m Start     ]8;id=248973;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py\main.py]8;;\:]8;id=346200;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py#51\51]8;;\
                             Loading Model
[12/20/23 14:25:01] [34mINFO    [39m [1m2023[22m-[1m12[22m-[1m20[22m [1m14:25:01[22m,[1m662[22m [1m[[22mINFO[1m][22m Load    ]8;id=333186;file:///home/thachhs/clau/clairaudience/clairaudience/../clairaudience/model.py\model.py]8;;\:]8;id=765987;file:///home/thachhs/clau/clairaudience/clairaudience/../clairaudience/model.py#782\782]8;;\
                             model from whisper pretrained
                             checkpoint: openai/whisper-large-v2
[12/20/23 14:25:03] [34mINFO    [39m [1m2023[22m-[1m12[22m-[1m20[22m [1m14:25:03[22m,[1m441[22m [1m[[22mINFO[1m][22m Start     ]8;id=50335;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py\main.py]8;;\:]8;id=195887;file:///home/thachhs/clau/clairaudience/./clairaudience/main.py#55\55]8;;\
                             Loading Dataset - gigaspeech
                    [34mINFO    [39m [1m2023[22m-[1m12[22m-[1m20[22m [1m14:25:03[22m,[1m469[22m [1m[[22mINFO[1m][22m  ]8;id=951235;file:///home/thachhs/clau/clairaudience/clairaudience/../clairaudience/data_process.py\data_process.py]8;;\:]8;id=371390;file:///home/thachhs/clau/clairaudience/clairaudience/../clairaudience/data_process.py#170\170]8;;\
                             Subsample the validation
                             dataset. Only use [1m100[22m samples
                             of the validation dataset
                             [1m(6750)
Traceback (most recent call last):
  File "/home/thachhs/clau/clairaudience/./clairaudience/main.py", line 131, in <module>
    run(cfg)
  File "/home/thachhs/clau/clairaudience/./clairaudience/main.py", line 92, in run
    trainer = ClairaudienceTrainer(
              ^^^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/clau/clairaudience/clairaudience/../clairaudience/trainer.py", line 63, in __init__
    super().__init__(
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/transformers/trainer_seq2seq.py", line 56, in __init__
    super().__init__(
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/transformers/trainer.py", line 551, in __init__
    self.init_git_repo(at_init=True)
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/transformers/trainer.py", line 3534, in init_git_repo
    self.repo = Repository(self.args.output_dir, clone_from=repo_name, token=self.args.hub_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/huggingface_hub/repository.py", line 516, in __init__
    self.clone_from(repo_url=clone_from)
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/huggingface_hub/repository.py", line 680, in clone_from
    raise EnvironmentError(
OSError: Tried to clone a repository in a non-empty folder that isn't a git repository ('/home/thachhs/clau/clairaudience/outputs/12_20_14_24_11'). If you really want to do this, do it manually:
 cd /home/thachhs/clau/clairaudience/outputs/12_20_14_24_11 && git init && git remote add origin && git pull origin main
 or clone repo to a new folder and move your existing files there afterwards.
/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.
  @numba.jit
Seed set to 42
Traceback (most recent call last):
  File "/home/thachhs/clau/clairaudience/./clairaudience/main.py", line 130, in <module>
    run(cfg)
  File "/home/thachhs/clau/clairaudience/./clairaudience/main.py", line 42, in run
    cache_file_name=f"{cache_dir}/{now}_setup_data.cache",
                       ^^^^^^^^^
UnboundLocalError: cannot access local variable 'cache_dir' where it is not associated with a value
/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.
  @numba.jit
Seed set to 42
Traceback (most recent call last):
  File "/home/thachhs/clau/clairaudience/./clairaudience/main.py", line 130, in <module>
    run(cfg)
  File "/home/thachhs/clau/clairaudience/./clairaudience/main.py", line 42, in run
    cache_file_name=f"./outputs/{cache_dir}/{now}_setup_data.cache",
                                 ^^^^^^^^^
UnboundLocalError: cannot access local variable 'cache_dir' where it is not associated with a value
/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.
  @numba.jit
Seed set to 42
Traceback (most recent call last):
  File "/home/thachhs/clau/clairaudience/./clairaudience/main.py", line 131, in <module>
    run(cfg)
  File "/home/thachhs/clau/clairaudience/./clairaudience/main.py", line 78, in run
    trainer = ClairaudienceTrainer(
              ^^^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/clau/clairaudience/clairaudience/../clairaudience/trainer.py", line 63, in __init__
    super().__init__(
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/transformers/trainer_seq2seq.py", line 56, in __init__
    super().__init__(
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/transformers/trainer.py", line 551, in __init__
    self.init_git_repo(at_init=True)
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/transformers/trainer.py", line 3534, in init_git_repo
    self.repo = Repository(self.args.output_dir, clone_from=repo_name, token=self.args.hub_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/huggingface_hub/repository.py", line 516, in __init__
    self.clone_from(repo_url=clone_from)
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/huggingface_hub/repository.py", line 680, in clone_from
    raise EnvironmentError(
OSError: Tried to clone a repository in a non-empty folder that isn't a git repository ('/home/thachhs/clau/clairaudience/outputs/12_20_14_42_17'). If you really want to do this, do it manually:
 cd /home/thachhs/clau/clairaudience/outputs/12_20_14_42_17 && git init && git remote add origin && git pull origin main
 or clone repo to a new folder and move your existing files there afterwards.
/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.
  @numba.jit
Seed set to 42
Cloning https://huggingface.co/aiface/12_20_14_45_17 into local empty directory.
WARNING:huggingface_hub.repository:Cloning https://huggingface.co/aiface/12_20_14_45_17 into local empty directory.
/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
[34m[1mwandb[39m[22m: Currently logged in as: [33mluusa2k1[39m. Use [1m`wandb login --relogin`[22m to force relogin
[34m[1mwandb[39m[22m: Tracking run with wandb version 0.16.1
[34m[1mwandb[39m[22m: Run data is saved locally in [35m[1m/home/thachhs/clau/clairaudience/wandb/run-20231220_144616-uw16unvp
[34m[1mwandb[39m[22m: Run [1m`wandb offline`[22m to turn off syncing.
[34m[1mwandb[39m[22m: Syncing run [33mbright-bee-1
[34m[1mwandb[39m[22m: ‚≠êÔ∏è View project at [34m[4mhttps://wandb.ai/luusa2k1/huggingface
[34m[1mwandb[39m[22m: üöÄ View run at [34m[4mhttps://wandb.ai/luusa2k1/huggingface/runs/uw16unvp
  0%|                                                  | 0/2000 [00:00<?, ?it/s]/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
WARNING:Clairaudience:`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...
Traceback (most recent call last):
  File "/home/thachhs/clau/clairaudience/./clairaudience/main.py", line 131, in <module>
    run(cfg)
  File "/home/thachhs/clau/clairaudience/./clairaudience/main.py", line 122, in run
    trainer.train(resume_from_checkpoint=resume_from_checkpoint)
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/transformers/trainer.py", line 1664, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/transformers/trainer.py", line 1940, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/transformers/trainer.py", line 2745, in training_step
    self.scaler.scale(loss).backward()
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/torch/autograd/function.py", line 274, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 141, in backward
    outputs = ctx.run_function(*detached_inputs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/clau/clairaudience/clairaudience/../clairaudience/model.py", line 446, in custom_forward
    return module(*inputs, output_attentions, use_cache)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/clau/clairaudience/clairaudience/../clairaudience/model.py", line 223, in forward
    hidden_states = self.fc2(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 10.75 GiB total capacity; 8.20 GiB already allocated; 115.31 MiB free; 8.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  0%|                                                  | 0/2000 [00:05<?, ?it/s]
Name: datasets
Version: 2.12.0
Summary: HuggingFace community-driven open-source library of datasets
Home-page: https://github.com/huggingface/datasets
Author: HuggingFace Inc.
Author-email: thomas@huggingface.co
License: Apache 2.0
Location: /home/thachhs/anaconda3/envs/clairau/lib/python3.11/site-packages
Requires: aiohttp, dill, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, pyarrow, pyyaml, requests, responses, tqdm, xxhash
